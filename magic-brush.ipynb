{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b2c3139",
   "metadata": {},
   "source": [
    "import json\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "import matplotlib.image as mpimg\n",
    "import os\n",
    "from openai import OpenAI\n",
    "import base64\n",
    "import requests\n",
    "import pathlib\n",
    "import textwrap\n",
    "import google.generativeai as genai\n",
    "from IPython.display import display\n",
    "from IPython.display import Markdown\n",
    "import http.client\n",
    "import typing\n",
    "import urllib.request\n",
    "\n",
    "import IPython.display\n",
    "from PIL import Image as PIL_Image\n",
    "from PIL import ImageOps as PIL_ImageOps"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79d70684",
   "metadata": {},
   "source": [
    "data_path = 'magic_brush/test'"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a4d65f9",
   "metadata": {},
   "source": [
    "f = open(f'{data_path}/series_instructions.json')\n",
    "instructions = json.load(f)\n",
    "f = open(f'{data_path}/global_descriptions.json')\n",
    "global_descriptions = json.load(f)\n",
    "f = open(f'{data_path}/local_descriptions.json')\n",
    "local_descriptions = json.load(f)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5497af9-bfaf-4d1a-bceb-27686e0a8019",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0162bc-10ae-48d9-a2c2-d2c9b4f03193",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0faea364-7e2d-4a7c-8df5-46a3dbdc657a",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293dd707-bc2b-4498-8545-b963ebbed05e",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "9c1bcc8a",
   "metadata": {},
   "source": [
    "len(instructions)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "3b773b62",
   "metadata": {},
   "source": [
    "idx = random.randint(0, len(instructions)-1)\n",
    "print(idx)\n",
    "sample = instructions[idx]\n",
    "f, axarr = plt.subplots(len(sample)+1, 1, figsize=(15, 15))\n",
    "f.tight_layout(pad=5.0)\n",
    "\n",
    "for idx, i in enumerate(sample):\n",
    "    if idx == 0:\n",
    "        print(path_in)\n",
    "        path_in = f'{data_path}/images/{sample[0][\"input\"].split(\"-\")[0]}/{sample[0][\"input\"]}'\n",
    "        axarr[0].imshow(mpimg.imread(path_in))\n",
    "        axarr[0].title.set_text(f'global input: {global_descriptions[sample[0][\"input\"].split(\"-\")[0]][sample[0][\"input\"]]}')\n",
    "        \n",
    "        path_out = f'{data_path}/images/{sample[0][\"input\"].split(\"-\")[0]}/{sample[0][\"output\"]}'\n",
    "        axarr[1].imshow(mpimg.imread(path_out))\n",
    "        title = f'global output: {global_descriptions[sample[idx][\"input\"].split(\"-\")[0]][sample[idx][\"output\"]]}'\n",
    "        title += f'\\n local output: {local_descriptions[sample[idx][\"input\"].split(\"-\")[0]][sample[idx][\"output\"]]}'\n",
    "        title += f'\\n instruction {i[\"instruction\"]}'\n",
    "        axarr[1].title.set_text(title)\n",
    "    else:\n",
    "        print(path_out)\n",
    "        path_out = f'{data_path}/images/{sample[idx][\"input\"].split(\"-\")[0]}/{sample[idx][\"output\"]}'\n",
    "        axarr[idx+1].imshow(mpimg.imread(path_out))\n",
    "        title = f'global output: {global_descriptions[sample[idx][\"input\"].split(\"-\")[0]][sample[idx][\"output\"]]}'\n",
    "        title += f'\\n local output: {local_descriptions[sample[idx][\"input\"].split(\"-\")[0]][sample[idx][\"output\"]]}'\n",
    "        title += f'\\n instruction {i[\"instruction\"]}'\n",
    "        axarr[idx+1].title.set_text(title)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93eef27b-73f5-4f90-84a7-2d79a1483a0b",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6e3119-63c7-44be-9060-005dc32aaef0",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b2fc88-3302-472b-bf7f-c2a6fe868554",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c437404-acd5-4a07-a573-12d8dcb1708c",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bdd1477-a883-4678-ba01-d4f73e0fbe2d",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf0efaa-e8e4-4956-bd39-f28282bc656e",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035b53d2-99a9-433e-8e00-52ca2e6cb260",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9390bf-915d-44c1-82a9-7a805818d272",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f209a136-1e4e-4cc3-8493-de544fce913c",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033b67df-74b0-4026-9476-3c416cb780f5",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ccad0b-8727-4c8a-bec3-f871778abba1",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744a5e28-e379-4c18-83ab-125585309e2a",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ec82f4-fdc5-4de2-9d04-c99162fec522",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dda5fa7-4eec-4c82-8cce-4c890cd8f0fa",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fee63cb-b90f-43ed-85ed-4f521882b384",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ef0c31-061d-48ff-8a17-7db1cc821a32",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44257053-b787-42e4-91d1-3f8e12acef5f",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca060f8",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "a405a61b",
   "metadata": {},
   "source": [
    "# GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f175b1a-33e8-4cc5-8a3f-facdad22405e",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fac64be-6552-4070-88c8-6f3188efa04a",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e33a97d-46ea-437e-a624-6e533cf09db9",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aecaaf5-403c-48df-bb71-429a18e84d58",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a15f45-4185-4d54-9253-a4675dcb4018",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0befee-c934-4545-916d-7e478d972327",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3533144c-3285-477c-92fb-4fd77e17f2b6",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeead074-c64c-4eca-b035-13d1119b52f5",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2b8723-a520-41e0-8327-194373fff600",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "bacaa651-6081-48bb-9b59-e6691f88c85c",
   "metadata": {},
   "source": [
    "api_key = os.getenv('OPENAI_API_KEY')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ca284206-6c1f-4a21-ba9a-d32ff24a668d",
   "metadata": {},
   "source": [
    "headers = {\n",
    "  \"Content-Type\": \"application/json\",\n",
    "  \"Authorization\": f\"Bearer {api_key}\"\n",
    "}"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "20b9f3cb",
   "metadata": {},
   "source": [
    "client = OpenAI()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d561966-0798-4db7-afb7-d2739edd5ecf",
   "metadata": {},
   "source": [
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-4-turbo\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": [\n",
    "        {\"type\": \"text\", \"text\": \"Whatâ€™s in this image?\"},\n",
    "        {\n",
    "          \"type\": \"image_url\",\n",
    "          \"image_url\": {\n",
    "            \"url\": \"https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg\",\n",
    "          },\n",
    "        },\n",
    "      ],\n",
    "    }\n",
    "  ],\n",
    "  max_tokens=300,\n",
    ")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6f0be40-e04a-4213-b4b4-54019d661d01",
   "metadata": {},
   "source": [
    "print(response.choices[0].message.content)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "04185941-ba24-460c-8b7b-3f8b3cbeda6b",
   "metadata": {},
   "source": [
    "## Local images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "76a10383-b1c0-45c0-b742-bb52f951d4b7",
   "metadata": {},
   "source": [
    "image_1 = \"/home/marco/PhD/VL_fine-grained/magic_brush/dev/images/267300/267300-output1.png\"\n",
    "image_2 = \"/home/marco/PhD/VL_fine-grained/magic_brush/dev/images/267300/267300-output2.png\""
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8932a0ff-b8bc-490f-a23c-5cf1c2b6616f",
   "metadata": {},
   "source": [
    "en_1  = encode_image(image_1)\n",
    "en_2 = encode_image(image_2)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bb3c2077-4df3-4060-958e-949097f4670e",
   "metadata": {},
   "source": [
    "def encode_image(image_path):\n",
    "  with open(image_path, \"rb\") as image_file:\n",
    "    return base64.b64encode(image_file.read()).decode('utf-8')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f19758-cd65-4655-897e-33bad386bffb",
   "metadata": {},
   "source": [
    "prompt = \"What is the most obvious difference between two images? If there is no obvious difference, choose None. 1. None, 2. eye, 3. ear, 4. food, 5. pillow, 6. flower, 7. plate\""
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ae992df0-1c79-4107-bd11-59a74cfcf99b",
   "metadata": {},
   "source": [
    "payload = {\n",
    "  \"model\": \"gpt-4-turbo\",\n",
    "  \"messages\": [\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": [\n",
    "        {\n",
    "          \"type\": \"text\",\n",
    "          \"text\": prompt\n",
    "        },\n",
    "        {\n",
    "          \"type\": \"image_url\",\n",
    "          \"image_url\": {\n",
    "            \"url\": f\"data:image/jpeg;base64,{en_1}\"\n",
    "          }\n",
    "        },\n",
    "        {\n",
    "          \"type\": \"image_url\",\n",
    "          \"image_url\": {\n",
    "            \"url\": f\"data:image/jpeg;base64,{en_2}\"\n",
    "          }\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  ],\n",
    "  \"max_tokens\": 300\n",
    "}"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7a67135c-d15c-43e7-81ea-da717677eeaf",
   "metadata": {},
   "source": [
    "response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fe5b693c-dacd-44d9-b0d4-f2f02199d231",
   "metadata": {},
   "source": [
    "print(response.json()['choices'][0]['message']['content'])"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "3346a633-299e-4ef2-a7c0-95a91a2e160b",
   "metadata": {},
   "source": [
    "# extract from gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "66e876c3-98af-4a4a-bd2b-f0d0f0a52f09",
   "metadata": {},
   "source": [
    "image_1 = \"/home/marco/PhD/VL_fine-grained/magic_brush/dev/images/129587/129587-output1.png\"\n",
    "en_1  = encode_image(image_1)\n",
    "extract_prompt = \"\"\"\n",
    "I want to extract as many components as possible from the provided images. Component examples are shown below. However, components are not limited to the following components. Please only provide the component name without any explanation and separate the component names with commons. If a human or an animal is shown in the images and hair, eye, hand, mouth, ear, and leg, etc. are visible, ensure to include them, Similarly, try to find all the components as detailed as possible. \n",
    "1. leg, 2. eye, 3. ear, 4. food, 5. pillow, 6. flower, 7. plate, 8. window, 9. door, 10. chair, 11. dining table, 12. sofa, 13. banana, 14. bowl, 15. sugar, 16. blender, 17. berry, 18. lizard, 19. watermelon, 20. motorcycle, 21. apple, 22. curtain, 23, cookies, 24, cake, 25. hair, 26, hat, 27, dresses, 28. bacon, 29. butter, 30, jam, 31, bread 32, surfboard, 33, t-shirt, 34, pants, 35, hands, 36. fridge, 37, plants, 38. cabinet, 39, sink, 40, car, 41, girl, 42, boy\n",
    "\"\"\""
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1c69f7ae-16b6-462c-8fe7-1e5e3cfd63b5",
   "metadata": {},
   "source": [
    "payload = {\n",
    "  \"model\": \"gpt-4-turbo\",\n",
    "  \"messages\": [\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": [\n",
    "        {\n",
    "          \"type\": \"text\",\n",
    "          \"text\": extract_prompt\n",
    "        },\n",
    "        {\n",
    "          \"type\": \"image_url\",\n",
    "          \"image_url\": {\n",
    "            \"url\": f\"data:image/png;base64,{en_1}\"\n",
    "          }\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  ],\n",
    "  \"max_tokens\": 300\n",
    "}"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "8b7acad1-6009-49e2-991c-42465435ca4d",
   "metadata": {},
   "source": [
    "response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "cc9e2f9a-6a8c-404c-ba98-e3bec2163c25",
   "metadata": {},
   "source": [
    "print(response.json()['choices'][0]['message']['content'])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8dcc596a-2842-48aa-873d-0221c4dc8356",
   "metadata": {},
   "source": [
    "response.json()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b982f07-29af-4422-a6c4-34f9aa438e81",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f9088a-55ab-4cbb-860a-248b5c1ca52c",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee19c461-8291-4443-90b7-31e77834adc7",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddaf2a28-0c07-4a46-9e52-cec7ee089be5",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "9a5ab75e-daa7-491d-a16d-14d50bf45cd0",
   "metadata": {},
   "source": [
    "# Gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "90793ba3-b0a0-473d-bc2e-d508a913f3e8",
   "metadata": {},
   "source": [
    "def to_markdown(text):\n",
    "  text = text.replace('â€¢', '  *')\n",
    "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17020ad6-ecc3-43f4-8938-dbc01ffb3d36",
   "metadata": {},
   "source": [
    "genai.configure(api_key='AIzaSyA_kbfVsa65btu37xRBPb9UyYytEHLKhd8')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a427b8ec-6e91-41a4-80cc-080027b77462",
   "metadata": {},
   "source": [
    "for m in genai.list_models():\n",
    "  if 'generateContent' in m.supported_generation_methods:\n",
    "          print(m.name)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b9ec0d9-7795-4053-b16f-f969b8c27a2e",
   "metadata": {},
   "source": [
    "model = genai.GenerativeModel(model_name=\"gemini-1.5-pro-latest\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51463ebc-7735-4be8-bd17-208354013c3f",
   "metadata": {},
   "source": [
    "# giraffe count\n",
    "image_1 = '/home/marco/PhD/VL_fine-grained/magic_brush/dev/images/381112/381112-input.png'\n",
    "image_2 = '/home/marco/PhD/VL_fine-grained/magic_brush/dev/images/381112/381112-output1.png'\n",
    "\n",
    "#dog eye\n",
    "# image_1 = \"/home/marco/PhD/VL_fine-grained/magic_brush/dev/images/267300/267300-output1.png\"\n",
    "# image_2 = \"/home/marco/PhD/VL_fine-grained/magic_brush/dev/images/267300/267300-output2.png\"\n",
    "\n",
    "#elephant\n",
    "# image_1 = \"/home/marco/PhD/VL_fine-grained/magic_brush/dev/images/129587/129587-output2.png\"\n",
    "# image_2 = \"/home/marco/PhD/VL_fine-grained/magic_brush/dev/images/129587/129587-output1.png\"\n",
    "\n",
    "#baconn\n",
    "# image_1 = \"/home/marco/PhD/VL_fine-grained/magic_brush/dev/images/140043/140043-input.png\"\n",
    "# image_2 = \"/home/marco/PhD/VL_fine-grained/magic_brush/dev/images/140043/140043-output1.png\"\n",
    "\n",
    "# # kitchen  \n",
    "# image_1 = \"/home/marco/PhD/VL_fine-grained/magic_brush/dev/images/512576/512576-input.png\"\n",
    "# image_2 = \"/home/marco/PhD/VL_fine-grained/magic_brush/dev/images/512576/512576-output1.png\"\n",
    "\n",
    "# # counter top\n",
    "# image_1 = \"/home/marco/PhD/VL_fine-grained/magic_brush/dev/images/125106/125106-input.png\"\n",
    "# image_2 = \"/home/marco/PhD/VL_fine-grained/magic_brush/dev/images/125106/125106-output1.png\"\n",
    "\n",
    "# #phone booth\n",
    "# image_1 = \"/home/marco/PhD/VL_fine-grained/magic_brush/dev/images/429011/429011-output2.png\"\n",
    "# image_2 = \"/home/marco/PhD/VL_fine-grained/magic_brush/dev/images/429011/429011-output3.png\"\n",
    "\n",
    "# # hair \n",
    "# image_1 = \"/home/marco/PhD/VL_fine-grained/magic_brush/dev/images/70952/70952-input.png\"\n",
    "# image_2 = \"/home/marco/PhD/VL_fine-grained/magic_brush/dev/images/70952/70952-output1.png\"\n",
    "\n",
    "# #\n",
    "# image_1 = \"/home/marco/PhD/VL_fine-grained/magic_brush/dev/images/560311/560311-input.png\"\n",
    "# image_2 = \"/home/marco/PhD/VL_fine-grained/magic_brush/dev/images/560311/560311-output1.png\"\n",
    "\n",
    "# #\n",
    "# image_1 = \"/home/marco/PhD/VL_fine-grained/magic_brush/dev/images/392687/392687-output1.png\"\n",
    "# image_2 = \"/home/marco/PhD/VL_fine-grained/magic_brush/dev/images/392687/392687-output2.png\"\n",
    "\n",
    "\n",
    "# #\n",
    "# image_1 = \"\"\n",
    "# image_2 = \"\"\n",
    "\n",
    "\n",
    "# #\n",
    "# image_1 = \"\"\n",
    "# image_2 = \"\""
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc3088d7-e54c-4d66-945d-3a2b90f9bbf1",
   "metadata": {},
   "source": [
    "img_1 = PIL_Image.open(image_1)\n",
    "img_2 = PIL_Image.open(image_2)\n",
    "prompt1 = \"\"\"\n",
    "Consider the following two images:\n",
    "Image 1:\n",
    "\"\"\"\n",
    "prompt2 = \"\"\"\n",
    "Image 2:\n",
    "\"\"\"\n",
    "# prompt3 = \"\"\"\n",
    "# What is the most obvious difference between two images? If there is no obvious difference, choose None. 1. None, 2. eye, 3. ear, 4. food, 5. pillow, 6. flower, 7. plate, 8.tongue\n",
    "# \"\"\"\n",
    "\n",
    "prompt3 = \"\"\"\n",
    "Which image has more giraffes?\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# prompt3 = \"\"\"\n",
    "# What is the most obvious difference between two images? If there is no obvious difference, choose None. None, elephant, ear, eye, mouth, leg, watermelon, grass, motorcycle, leaves, tree.\n",
    "# \"\"\"\n",
    "\n",
    "# prompt3 = \"\"\"\n",
    "# What is the most obvious difference between two images? If there is no obvious difference, choose None. None, plate, French toast, butter, powdered sugar, jam, bacon, coffee, cup, table.\n",
    "# \"\"\"\n",
    "\n",
    "# prompt3 = \"\"\"\n",
    "# What is the most obvious difference between two images? If there is no obvious difference, choose None. None, ceiling fan, cabinets, stove, refrigerator, window, curtain, plates, dining table, chair, bottle, wall art, sink, countertop, flowers, pot, pan, kitchen utensils, ceiling light, wall clock, tablecloth.\n",
    "# \"\"\"\n",
    "\n",
    "# prompt3 = \"\"\"\n",
    "# What is the most obvious difference between two images? If there is no obvious difference, choose None. None, street lamp, phone booth, windows, building, dog, car, traffic light, siren, backpack, person, street, sidewalk, suit, tie. \n",
    "# \"\"\"\n",
    "\n",
    "# prompt3 = \"\"\"\n",
    "# What is the most obvious difference between two images? If there is no obvious difference, choose None. None, \n",
    "# hat, ear, eye, hair, hand, mouth, apron, wine glass, shirt, watch, ring, wall art, wall, lighting. \n",
    "# \"\"\"\n",
    "\n",
    "# prompt3 = \"\"\"\n",
    "# What is the most obvious difference between two images? If there is no obvious difference, choose None. None, \n",
    "# refrigerator, cabinets, sink, faucet, window, plant, paper towel, box, chair, curtain, wall, ceiling, light fixture. \n",
    "# \"\"\"\n",
    "\n",
    "# prompt3 = \"\"\"\n",
    "# What is the most obvious difference between two images? If there is no obvious difference, choose None. None, girl, boy, tree, skateboard, jacket, pants, bodysuit, sea, sky, parking block, trash can, grass, sidewalk, horizon. \n",
    "# \"\"\"\n",
    "\n",
    "# prompt3 = \"\"\"\n",
    "# What is the most obvious difference between two images?\n",
    "# \"\"\""
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "fce8e6c2-234a-4e4f-9f81-d332ae20b4b2",
   "metadata": {},
   "source": [
    "contents = [\n",
    "    prompt1,\n",
    "    img_1,\n",
    "    prompt2,\n",
    "    img_2,\n",
    "    prompt3\n",
    "]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "65e588d7-f383-483b-9da2-e2481a156f9e",
   "metadata": {},
   "source": [
    "responses = model.generate_content(\n",
    "    contents,\n",
    "    stream=True,\n",
    ")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "1df64f6e-149a-4e9d-b8d3-5c30ca7201d0",
   "metadata": {},
   "source": [
    "print(\"\\n-------Response--------\")\n",
    "for response in responses:\n",
    "    print(response.text, end=\"\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5c54a2-5cc0-45d6-90b7-c95eeef46174",
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vl_compare",
   "language": "python",
   "name": "vl_compare"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
